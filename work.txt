Using the GPT architecture for a Time Series Foundation model makes sense because of its autoregressive nature. Time series forecasting requires predicting future values based on past observations, and GPT's autoregressive design aligns perfectly with this. GPT generates the next token (or time step) by conditioning on all previous inputs, making it ideal for sequential data like time series. 
